{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "youtube_History_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEIGI367i9MM"
      },
      "source": [
        "#Youtube Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwM3_bKnYlzu"
      },
      "source": [
        "from datetime import datetime, timedelta, time \n",
        "flag=0\n",
        "ip= input(\"Today (0),This Week (1),This Month (2),This Year (3),None (4):\")\n",
        "sd=None\n",
        "ed=None\n",
        "try :\n",
        "  ip=int(ip)\n",
        "except:\n",
        "  ip=ip\n",
        "if ip == 0:\n",
        "  sd=datetime.now()\n",
        "  ed=datetime.now()\n",
        "elif ip == 1:\n",
        "  today = datetime.now().date()\n",
        "  sd= today - timedelta(days=today.weekday())\n",
        "  sd=datetime.combine(sd, time(0, 0))\n",
        "  #sd=datetime.today().replace(day=1)\n",
        "  ed=datetime.now()\n",
        "elif ip == 2:\n",
        "  sd=datetime.today().replace(day=1)\n",
        "  ed=datetime.now()\n",
        "elif ip == 3:\n",
        "  sd=datetime.today().replace(day=1,month=1)\n",
        "  ed=datetime.now()\n",
        "else:\n",
        "  flag=1\n",
        "try :\n",
        "  print(\"Start Date :\"+sd.strftime(\"%d-%m-%Y\"))\n",
        "  print(\"End Date :\"+ed.strftime(\"%d-%m-%Y\"))\n",
        "except:\n",
        "  print(\"No Start and End Time Specified as of Now\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zv9inv2MlZP"
      },
      "source": [
        "from datetime import datetime, timedelta, time\n",
        "try:\n",
        "    flag\n",
        "except NameError:\n",
        "  ip=3\n",
        "  print(\"Enter in Format of dd-mm-yyyy\\n\")\n",
        "  sd = input(\"Enter Start Date:\")\n",
        "  ed = input(\"Enter End Date:\")\n",
        "  try:\n",
        "    sd = datetime.strptime(sd, '%d-%m-%Y')\n",
        "  except:\n",
        "    sd = datetime.now()\n",
        "  try:\n",
        "    ed = datetime.strptime(sd, '%d-%m-%Y')\n",
        "  except:\n",
        "    ed = datetime.now()\n",
        "\n",
        "  print(\"Start Date :\"+sd.strftime(\"%d-%m-%Y\"))\n",
        "  print(\"End Date :\"+ed.strftime(\"%d-%m-%Y\"))    \n",
        "else:\n",
        "  if flag == 1:\n",
        "    print(\"Enter in Format of dd-mm-yyyy\\n\")\n",
        "    sd = input(\"Enter Start Date:\")\n",
        "    ed = input(\"Enter End Date:\")\n",
        "    try:\n",
        "      sd = datetime.strptime(sd, '%d-%m-%Y')\n",
        "    except:\n",
        "      sd = datetime.now()\n",
        "    try:\n",
        "      ed = datetime.strptime(sd, '%d-%m-%Y')\n",
        "    except:\n",
        "      ed = datetime.now()\n",
        "    ip=3\n",
        "\n",
        "  print(\"Start Date :\"+sd.strftime(\"%d-%m-%Y\"))\n",
        "  print(\"End Date :\"+ed.strftime(\"%d-%m-%Y\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLXocjP8i1-n"
      },
      "source": [
        "import json\n",
        "from wordcloud import WordCloud, STOPWORDS \n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd \n",
        "import matplotlib.dates as mdates\n",
        "from datetime import datetime, timedelta, time\n",
        "from scipy.ndimage.filters import gaussian_filter1d\n",
        "import traceback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-FFHMbBjXxK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1kzXOq8jKIa"
      },
      "source": [
        "# Watch History Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNdiFNLSjPSC"
      },
      "source": [
        "# Get this file from takeout.google.com\n",
        "# To speed up the process, only select \"Google Chrome\"\n",
        "# and within \"Google Chrome\" only select \"Browser History\".\n",
        "# This file should be ready in a couple minutes\n",
        "with open(r'/content/drive/My Drive/Internet_History_Analysis_Data/watch-history.json', encoding='utf8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "temp=[]\n",
        "for entry in data:\n",
        "  v=entry['time']\n",
        "  try:\n",
        "      v=datetime.strptime(v, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "  except:\n",
        "      v=datetime.strptime(v, '%Y-%m-%dT%H:%M:%SZ')\n",
        "  if  v > ed :\n",
        "      continue\n",
        "  if (not (v >= sd and v <= ed )):\n",
        "      break\n",
        "  temp.append(entry)\n",
        "data=temp\n",
        "\n",
        "comment_words = '' \n",
        "stopwords = set(STOPWORDS) \n",
        "#print(type(stopwords))\n",
        "stopwords.add('Watched')\n",
        "stopwords.add('Visited')\n",
        "# iterate through the csv file \n",
        "for entry in data:\n",
        "    val = entry['title']\n",
        "    #print(val)\n",
        "    # typecaste each val to string \n",
        "    val = str(val)\n",
        "    # split the value \n",
        "    tokens = val.split() \n",
        "    # Converts each token into lowercase \n",
        "    for i in range(len(tokens)): \n",
        "        tokens[i] = tokens[i].lower() \n",
        "    \n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "wordcloud = WordCloud(width = 800, height = 800, \n",
        "                background_color ='white', \n",
        "                stopwords = stopwords, \n",
        "                min_font_size = 10).generate(comment_words) \n",
        "\n",
        "# plot the WordCloud image                   \n",
        "plt.figure(figsize = (8, 8), facecolor = None) \n",
        "plt.imshow(wordcloud) \n",
        "plt.axis(\"off\") \n",
        "plt.tight_layout(pad = 0) \n",
        "\n",
        "plt.show() \n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6jMDw4HilOl"
      },
      "source": [
        "# Search History Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsf-Fr4Riyt1"
      },
      "source": [
        "# Get this file from takeout.google.com\n",
        "# To speed up the process, only select \"Google Chrome\"\n",
        "# and within \"Google Chrome\" only select \"Browser History\".\n",
        "# This file should be ready in a couple minutes\n",
        "with open(r'/content/drive/My Drive/Internet_History_Analysis_Data/search-history.json', encoding='utf8') as file:\n",
        "    data = json.load(file)\n",
        "temp=[]\n",
        "for entry in data:\n",
        "  v=entry['time']\n",
        "  try:\n",
        "      v=datetime.strptime(v, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "  except:\n",
        "      v=datetime.strptime(v, '%Y-%m-%dT%H:%M:%SZ')\n",
        "  if  v > ed :\n",
        "      continue\n",
        "  if (not (v >= sd and v <= ed )):\n",
        "      break\n",
        "  temp.append(entry)\n",
        "data=temp\n",
        "\n",
        "\n",
        "comment_words = '' \n",
        "stopwords = set(STOPWORDS) \n",
        "#print(type(stopwords))\n",
        "stopwords.add('Searched')\n",
        "#stopwords.add('Visited')\n",
        "# iterate through the csv file \n",
        "for entry in data:\n",
        "    val = entry['title']\n",
        "    #print(val)\n",
        "    # typecaste each val to string \n",
        "    val = str(val)\n",
        "    # split the value \n",
        "    tokens = val.split() \n",
        "    # Converts each token into lowercase \n",
        "    for i in range(len(tokens)): \n",
        "        tokens[i] = tokens[i].lower() \n",
        "    \n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "wordcloud = WordCloud(width = 800, height = 800, \n",
        "                background_color ='white', \n",
        "                stopwords = stopwords, \n",
        "                min_font_size = 10).generate(comment_words) \n",
        "\n",
        "# plot the WordCloud image                   \n",
        "plt.figure(figsize = (8, 8), facecolor = None) \n",
        "plt.imshow(wordcloud) \n",
        "plt.axis(\"off\") \n",
        "plt.tight_layout(pad = 0) \n",
        "\n",
        "plt.show() \n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYRkkexL-Hy6"
      },
      "source": [
        "# Get this file from takeout.google.com\n",
        "# To speed up the process, only select \"Google Chrome\"\n",
        "# and within \"Google Chrome\" only select \"Browser History\".\n",
        "# This file should be ready in a couple minutes\n",
        "with open(r'/content/drive/My Drive/Internet_History_Analysis_Data/search-history.json', encoding='utf8') as file:\n",
        "    data1 = json.load(file)\n",
        "with open(r'/content/drive/My Drive/Internet_History_Analysis_Data/watch-history.json', encoding='utf8') as file:\n",
        "    data2 = json.load(file)\n",
        "\n",
        "temp=[]\n",
        "for entry in data1:\n",
        "  v=entry['time']\n",
        "  try:\n",
        "      v=datetime.strptime(v, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "  except:\n",
        "      v=datetime.strptime(v, '%Y-%m-%dT%H:%M:%SZ')\n",
        "  if  v > ed :\n",
        "      continue\n",
        "  if (not (v >= sd and v <= ed )):\n",
        "      break\n",
        "  temp.append(entry)\n",
        "for entry in data2:\n",
        "  v=entry['time']\n",
        "  try:\n",
        "      v=datetime.strptime(v, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "  except:\n",
        "      v=datetime.strptime(v, '%Y-%m-%dT%H:%M:%SZ')\n",
        "  if  v > ed :\n",
        "      continue\n",
        "  if (not (v >= sd and v <= ed )):\n",
        "      break\n",
        "  temp.append(entry)  \n",
        "data=temp\n",
        "times = []\n",
        "# Histogram of when sites are loaded. \n",
        "# This shows most/least active time of day\n",
        "daily_minute = [0] * 1440\n",
        "day_of_week = [0] * 7\n",
        "# Number of visits for each day\n",
        "daily_visits = {}\n",
        "for entry in data: \n",
        "    val = entry['time']\n",
        "\n",
        "    #print(val)\n",
        "    # Average time of day\n",
        "    try:\n",
        "      val=datetime.strptime(val, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "    except:\n",
        "      val=datetime.strptime(val, '%Y-%m-%dT%H:%M:%SZ')\n",
        "    times.append(val)\n",
        "    time_idx = val.hour*60 + val.minute\n",
        "    daily_minute[time_idx] += 1\n",
        "\n",
        "    # Weekly usage\n",
        "    day_of_week[val.weekday()] += 1\n",
        "    \n",
        "    # Number of webpages per day\n",
        "    day_idx = val.strftime('%Y-%m-%d')\n",
        "    if day_idx in daily_visits.keys():\n",
        "        daily_visits[day_idx] += 1\n",
        "    else:\n",
        "        daily_visits[day_idx] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1jJv9uaA3bD"
      },
      "source": [
        "# Daily Activity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFjRi94bvAgF"
      },
      "source": [
        "%matplotlib inline\n",
        "daily = dict(daily_visits)\n",
        "sorted_visits = sorted(daily.items(), key=lambda x:x[1], reverse=True)\n",
        "\n",
        "total = 0\n",
        "for day in sorted_visits:\n",
        "    total += day[1]\n",
        "ave = int(total / len(sorted_visits))\n",
        "print('You Watched and Searched {}  in the last {} days!'.format(len(data), len(sorted_visits)))\n",
        "print('That\\'s {} Watch&Search per day'.format(ave))\n",
        "print()\n",
        "print(\"Your most active days were:\")\n",
        "try :\n",
        "  for i in range(5):\n",
        "      print(\"\\t{}) {} with {} Watch&Search\".format(str(i+1), sorted_visits[i][0], sorted_visits[i][1]))\n",
        "except :\n",
        "  print()\n",
        "if ip==3:\n",
        "  try :\n",
        "      start_day = datetime.strptime(list(daily.items())[-1][0], '%Y-%m-%d')\n",
        "      end_day = datetime.strptime(list(daily.items())[0][0], '%Y-%m-%d')\n",
        "      start_day=sd\n",
        "      end_day=ed\n",
        "      #print(start_day)\n",
        "      #print(end_day)\n",
        "      date_list = mdates.drange(start_day, end_day+timedelta(days=1), timedelta(days=1))\n",
        "      for date in date_list:\n",
        "          if not mdates.num2date(date).strftime('%Y-%m-%d') in daily.keys():\n",
        "              daily[mdates.num2date(date).strftime('%Y-%m-%d')] = 0\n",
        "\n",
        "      sorted_visits = sorted(daily.items(), key = lambda x:datetime.strptime(x[0], '%Y-%m-%d'), reverse=False)\n",
        "      #print(sorted_visits)\n",
        "      plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%b '%y\"))\n",
        "      plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
        "      plt.gca().axes.set_ylabel('Number of Watch&Search Per Day')\n",
        "      plt.gca().axes.set_xlabel('Day')\n",
        "      plt.title('Watch&Search per Day')\n",
        "\n",
        "      visits = [x[1] for x in sorted_visits]\n",
        "      #print(visits)\n",
        "      visits_smoothed = gaussian_filter1d(visits, sigma=12)\n",
        "      #print(visits_smoothed)\n",
        "      plt.plot(date_list, visits_smoothed, '-', color='black')\n",
        "      plt.gcf().autofmt_xdate()\n",
        "      plt.grid()\n",
        "      plt.show()\n",
        "  except Exception as e: \n",
        "      #print(e)\n",
        "      traceback.print_exc()\n",
        "      print(\"Sorry Cannot Able to Plot the Graph within given Date range !!\")\n",
        "else:\n",
        "  try :\n",
        "      start_day = datetime.strptime(list(daily.items())[-1][0], '%Y-%m-%d')\n",
        "      end_day = datetime.strptime(list(daily.items())[0][0], '%Y-%m-%d')\n",
        "      start_day=sd\n",
        "      end_day=ed\n",
        "      #print(start_day)\n",
        "      #print(end_day)\n",
        "      date_list = mdates.drange(start_day, end_day+timedelta(days=1), timedelta(days=1))\n",
        "      for date in date_list:\n",
        "          if not mdates.num2date(date).strftime('%Y-%m-%d') in daily.keys():\n",
        "              daily[mdates.num2date(date).strftime('%Y-%m-%d')] = 0\n",
        "\n",
        "      sorted_visits = sorted(daily.items(), key = lambda x:datetime.strptime(x[0], '%Y-%m-%d'), reverse=False)\n",
        "      #print(sorted_visits)\n",
        "      if ip==1:\n",
        "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))\n",
        "        plt.title('Watch&Search per Day')\n",
        "      elif ip==2:\n",
        "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%d\"))\n",
        "        now = datetime.now()\n",
        "        plt.title(\"Watch&Search per Day in month of %s\" % (now.strftime('%B %Y')))\n",
        "\n",
        "\n",
        "      plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
        "      plt.gca().axes.set_ylabel('Number of Watch&Search Per Day')\n",
        "      plt.gca().axes.set_xlabel('Day')\n",
        "      \n",
        "\n",
        "      visits = [x[1] for x in sorted_visits]\n",
        "      #print(visits)\n",
        "      #visits_smoothed = gaussian_filter1d(visits, sigma=12)\n",
        "      #print(visits_smoothed)\n",
        "      plt.plot(date_list, visits, '-', color='black')\n",
        "      plt.gcf().autofmt_xdate()\n",
        "      plt.grid()\n",
        "      plt.show()\n",
        "  except Exception as e: \n",
        "      #print(e)\n",
        "      traceback.print_exc()\n",
        "      print(\"Sorry Cannot Able to Plot the Graph within given Date range !!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba17WwFwBAOp"
      },
      "source": [
        "xlabs = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "plt.xticks(range(7),xlabs)\n",
        "plt.gca().axes.set_yticklabels([])\n",
        "plt.gca().axes.set_ylabel('Average Weekly Usage')\n",
        "plt.gca().axes.set_xlabel('Day of the Week')\n",
        "plt.title('Average Youtube Usage per Week')\n",
        "plt.bar(range(7), day_of_week, color='black');\n",
        "# plt.gcf().autofmt_xdate()\n",
        "# plt.grid()\n",
        "plt.show()\n",
        "\n",
        "max_index = day_of_week.index(max(day_of_week))\n",
        "min_index = day_of_week.index(min(day_of_week))\n",
        "print('It looks like you\\'re most active on {} and least active on {}'\n",
        "      .format(xlabs[max_index], xlabs[min_index]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZWkX1xZBOzR"
      },
      "source": [
        "# Average Daily Usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0soWxunUBMU5"
      },
      "source": [
        "start_time = datetime(12, 12, 12, 0, 0)\n",
        "#print(start_time)\n",
        "end_time = start_time + timedelta(hours=24)\n",
        "time_list = mdates.drange(start_time, end_time, timedelta(minutes=1))\n",
        "hour_list = mdates.drange(start_time, end_time+timedelta(hours=1), timedelta(hours=2))\n",
        "if ip==3:\n",
        "  daily_minute_smoothed = gaussian_filter1d(daily_minute, sigma=14)\n",
        "else :\n",
        "  daily_minute_smoothed = daily_minute\n",
        "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%I %p'))\n",
        "plt.xticks(hour_list)\n",
        "plt.gca().axes.set_yticklabels([])\n",
        "plt.gca().axes.set_ylabel('Average Number of Watch&Search')\n",
        "plt.gca().axes.set_xlabel('Time of Day (Minutes)')\n",
        "plt.title('Average Youtube Usage per Day')\n",
        "plt.plot(time_list, daily_minute_smoothed, '-', color='black');\n",
        "plt.gcf().autofmt_xdate()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "max_index = list(daily_minute_smoothed).index(max(daily_minute_smoothed))\n",
        "min_index = list(daily_minute_smoothed).index(min(daily_minute_smoothed))\n",
        "most_active = (mdates.num2date(time_list[max_index]).strftime('%I:%m %p'))\n",
        "least_active = (mdates.num2date(time_list[min_index]).strftime('%I:%m %p'))\n",
        "print('It looks like you\\'re most active around {} and least active around {}'\n",
        "      .format(most_active, least_active))\n",
        "most_active = '{:02d}:{:02d}'.format(*divmod(max_index, 60))\n",
        "least_active = '{:02d}:{:02d}'.format(*divmod(min_index, 60))\n",
        "print('Can be Accurately It looks like you\\'re most active around {} and least active around {}'\n",
        "      .format(most_active, least_active))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}